{"cells":[{"cell_type":"markdown","id":"3b3708a7-4633-49f0-9a76-a7021e769fcc","metadata":{"id":"3b3708a7-4633-49f0-9a76-a7021e769fcc"},"source":["# Audio Transcription"]},{"cell_type":"markdown","id":"223284df-c731-4123-a12a-c93ae561742e","metadata":{"id":"223284df-c731-4123-a12a-c93ae561742e"},"source":["## Audio Track of Interview - 2 Speakers"]},{"cell_type":"code","execution_count":null,"id":"9cffbf5a-e409-43ab-9852-a41ae7151ce4","metadata":{"id":"9cffbf5a-e409-43ab-9852-a41ae7151ce4"},"outputs":[],"source":["import librosa"]},{"cell_type":"code","execution_count":null,"id":"279f32e9-fbfb-4315-a444-4e246c86c04c","metadata":{"id":"279f32e9-fbfb-4315-a444-4e246c86c04c"},"outputs":[],"source":["audio_path = 'interview.mp3'\n","y, sr = librosa.load(audio_path, sr=None)"]},{"cell_type":"code","execution_count":null,"id":"db55b99a-080a-4089-9c8d-549301a20fe1","metadata":{"id":"db55b99a-080a-4089-9c8d-549301a20fe1"},"outputs":[],"source":["from IPython.display import Audio\n","\n","# Play the loaded audio\n","Audio(data=y, rate=sr)"]},{"cell_type":"markdown","id":"519aabca-e77a-4dfe-9540-8fea61ff2fbb","metadata":{"id":"519aabca-e77a-4dfe-9540-8fea61ff2fbb"},"source":["## Pyannote Audio Transcription"]},{"cell_type":"code","execution_count":null,"id":"e20e269f-69e7-42e6-9ffb-40d3f7eda093","metadata":{"id":"e20e269f-69e7-42e6-9ffb-40d3f7eda093"},"outputs":[],"source":["#!pip install --upgrade pyannote.audio"]},{"cell_type":"markdown","id":"e7c6adc7-d959-4911-9c6f-21db5c853dbc","metadata":{"id":"e7c6adc7-d959-4911-9c6f-21db5c853dbc"},"source":["This is a **gated model**! You must request access that is linked to your HF token at both these links:\n","* https://huggingface.co/pyannote/speaker-diarization-3.1\n","* https://huggingface.co/pyannote/segmentation-3.0"]},{"cell_type":"markdown","id":"28d79ea4-0fca-40f3-9660-3f7fbeb5a8a2","metadata":{"id":"28d79ea4-0fca-40f3-9660-3f7fbeb5a8a2"},"source":["## Processing\n","\n","If you have fully setup CUDA with your NVIDIA card, you may want to consider trying to use your GPU. Note: We do not support installation or setup support in this course for CUDA due to the difficuly in trying to help someone install this without access to their computer.\n","\n","```python\n","import torch\n","pipeline.to(torch.device(\"cuda\"))\n","```"]},{"cell_type":"markdown","id":"b188acc2-6739-414e-8848-c7015e544f2f","metadata":{"id":"b188acc2-6739-414e-8848-c7015e544f2f"},"source":["## Pipeline"]},{"cell_type":"code","source":["\n","from huggingface_hub import login\n","login()"],"metadata":{"id":"SXkKryWvCCnN"},"id":"SXkKryWvCCnN","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"dfcd7622-b698-47d1-b71f-848438f2000c","metadata":{"id":"dfcd7622-b698-47d1-b71f-848438f2000c"},"outputs":[],"source":["%%time\n","from pyannote.audio import Pipeline\n","\n","diarization_pipeline = Pipeline.from_pretrained(\n","    \"pyannote/speaker-diarization-3.1\", use_auth_token=\"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\"\n",")"]},{"cell_type":"markdown","id":"1f107a16-ce52-4d56-b694-bd35a01ed085","metadata":{"id":"1f107a16-ce52-4d56-b694-bd35a01ed085"},"source":[]},{"cell_type":"code","execution_count":null,"id":"24e1c774-6b0b-4880-80f9-a9ca8c90d36f","metadata":{"id":"24e1c774-6b0b-4880-80f9-a9ca8c90d36f"},"outputs":[],"source":["%%time\n","# This will take a very long time on less powerful computers!\n","from pyannote.audio.pipelines.utils.hook import ProgressHook\n","with ProgressHook() as hook:\n","    diarization = diarization_pipeline(\"interview.mp3\", hook=hook)"]},{"cell_type":"code","execution_count":null,"id":"57872b10-fdef-49f4-8ae7-c89a2e940acf","metadata":{"id":"57872b10-fdef-49f4-8ae7-c89a2e940acf"},"outputs":[],"source":["diarization"]},{"cell_type":"code","execution_count":null,"id":"f92ba2e2-cb97-4a2e-b8c2-3bcded38f1c9","metadata":{"id":"f92ba2e2-cb97-4a2e-b8c2-3bcded38f1c9"},"outputs":[],"source":["diarization.chart()"]},{"cell_type":"code","execution_count":null,"id":"d47c7803-d589-40d0-976c-0c80652b9ef1","metadata":{"id":"d47c7803-d589-40d0-976c-0c80652b9ef1"},"outputs":[],"source":["diarization.discretize()"]},{"cell_type":"code","execution_count":null,"id":"2a3d1a54-b890-4875-adb4-4823f565b12d","metadata":{"id":"2a3d1a54-b890-4875-adb4-4823f565b12d"},"outputs":[],"source":["# print the result\n","for turn, _, speaker in diarization.itertracks(yield_label=True):\n","    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"]},{"cell_type":"markdown","id":"8f59e9bd-6f96-4055-81d1-28e1075f62b6","metadata":{"id":"8f59e9bd-6f96-4055-81d1-28e1075f62b6"},"source":["### Function to combine total start and stop speaking times"]},{"cell_type":"code","execution_count":null,"id":"562ac906-2e5b-4337-b70d-07870630fc74","metadata":{"id":"562ac906-2e5b-4337-b70d-07870630fc74"},"outputs":[],"source":["def consolidate_speaker_segments(diarization):\n","    consolidated_segments = []\n","    current_speaker = None\n","    segment_start = None\n","\n","    for turn, _, speaker in diarization.itertracks(yield_label=True):\n","        if speaker != current_speaker:\n","            if current_speaker is not None:\n","                consolidated_segments.append((current_speaker, segment_start, turn.start))\n","            current_speaker = speaker\n","            segment_start = turn.start\n","        segment_end = turn.end\n","\n","    if current_speaker is not None:\n","        consolidated_segments.append((current_speaker, segment_start, segment_end))\n","\n","    return consolidated_segments"]},{"cell_type":"code","execution_count":null,"id":"dc5e05e2-1088-45b3-a879-3462a16f385f","metadata":{"id":"dc5e05e2-1088-45b3-a879-3462a16f385f"},"outputs":[],"source":["# Example usage with the provided diarization object:\n","segments = consolidate_speaker_segments(diarization)"]},{"cell_type":"code","execution_count":null,"id":"e0a68a7d-bbb9-4f9d-8033-828b47ddeff4","metadata":{"id":"e0a68a7d-bbb9-4f9d-8033-828b47ddeff4"},"outputs":[],"source":["segments"]},{"cell_type":"code","execution_count":null,"id":"3e9837d7-5020-4a27-aa52-0752113f6162","metadata":{"id":"3e9837d7-5020-4a27-aa52-0752113f6162"},"outputs":[],"source":["for speaker, start, end in segments:\n","    print(f\"speaker_{speaker} start={start:.1f}s stop={end:.1f}s\")"]},{"cell_type":"code","execution_count":null,"id":"3816d080-d6f6-4f81-ac78-2c5e935d2c1b","metadata":{"id":"3816d080-d6f6-4f81-ac78-2c5e935d2c1b"},"outputs":[],"source":["!pip install pydub"]},{"cell_type":"code","execution_count":null,"id":"fb828eca-5591-4c0b-be3f-75d89e42c518","metadata":{"id":"fb828eca-5591-4c0b-be3f-75d89e42c518"},"outputs":[],"source":["from pydub import AudioSegment\n","import os\n","\n","def split_audio_segments(audio_file, segments, output_dir='segmented_audio'):\n","    # Ensure the output directory exists\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Load the audio file\n","    audio = AudioSegment.from_file(audio_file)\n","\n","    # Iterate over the segments and export each one\n","    for idx, (speaker, start, end) in enumerate(segments):\n","        # Calculate start and end in milliseconds\n","        start_ms = start * 1000\n","        end_ms = end * 1000\n","\n","        # Extract the segment\n","        segment = audio[start_ms:end_ms]\n","\n","        # Create the output file name\n","        speaker_label = speaker.split('_')[-1]  # Get speaker identifier\n","        output_file = os.path.join(output_dir, f\"{idx:02d}_SPEAKER{speaker_label}_START{start:.0f}_STOP{end:.0f}.mp3\")\n","\n","        # Export the segment\n","        segment.export(output_file, format=\"mp3\")\n","        print(f\"Exported {output_file}\")"]},{"cell_type":"code","execution_count":null,"id":"15ba0bf9-fa29-4b30-a19d-73f08997c3ad","metadata":{"id":"15ba0bf9-fa29-4b30-a19d-73f08997c3ad"},"outputs":[],"source":["split_audio_segments('interview.mp3',segments)"]},{"cell_type":"markdown","id":"4426225d-521f-4e9c-aeb9-4b3c903396b8","metadata":{"id":"4426225d-521f-4e9c-aeb9-4b3c903396b8"},"source":["# Speech Transcription"]},{"cell_type":"code","execution_count":null,"id":"8c27f15a-7651-4b01-affb-ff4f1a4c65a1","metadata":{"id":"8c27f15a-7651-4b01-affb-ff4f1a4c65a1"},"outputs":[],"source":["# Use a pipeline as a high-level helper\n","from transformers import pipeline\n","\n","# model = https://huggingface.co/facebook/wav2vec2-base-960h\n","pipe = pipeline(\"automatic-speech-recognition\")"]},{"cell_type":"code","execution_count":null,"id":"5e68afef-dd91-4657-98a0-2e3f56b2876a","metadata":{"id":"5e68afef-dd91-4657-98a0-2e3f56b2876a"},"outputs":[],"source":["import os\n","import re\n","\n","def process_segmented_files(directory='segmented_audio'):\n","    # Ensure the directory exists\n","    if not os.path.exists(directory):\n","        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n","\n","    # List all files in the directory\n","    files = os.listdir(directory)\n","\n","\n","    # Process each file\n","    for file in files:\n","        file_path = os.path.join(directory, file)\n","        if os.path.isfile(file_path):\n","            text = pipe(file_path)['text']\n","            num,speaker,time_start,time_stop = file.split('_')\n","            time_stop = time_stop.replace(\".mp3\",'')\n","            print(f\"{speaker}-- {time_start}sec {time_stop}sec:\\n{text}\")\n","            print('\\n\\n')"]},{"cell_type":"code","execution_count":null,"id":"bc8b7f95-0709-4ebb-9a14-a37190f4fe66","metadata":{"id":"bc8b7f95-0709-4ebb-9a14-a37190f4fe66"},"outputs":[],"source":["process_segmented_files()"]},{"cell_type":"code","execution_count":null,"id":"81f34989-cd2f-4f96-b508-aca3f161e7e4","metadata":{"id":"81f34989-cd2f-4f96-b508-aca3f161e7e4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}